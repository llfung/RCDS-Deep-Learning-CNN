{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "received-exercise",
   "metadata": {},
   "source": [
    "# 1.2 Neural network basics\n",
    "\n",
    "In this notebook, we construct a basic neural network in PyTorch. We attempt to only provide a bare-bone example for clarity. For another such example, please see [PyTorch's homepage](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "\n",
    "<!--\n",
    "- [Building the network](#Building-the-network)\n",
    "- [Training the network](#Training-the-network)\n",
    "- [Testing the network](#Testing-the-network)\n",
    "- [Exercises](#Exercises)\n",
    "-->\n",
    "\n",
    "First, we import the libraries and load the data. You have already seen this code in notebook 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "otherwise-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# We load a training set\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# And withhold some data for testing\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=256, shuffle=True, num_workers=4, pin_memory=True) # Torch's default dataloader is sequential and slow. Use num_worker may speed up the process a bit, but still CPU-driven. Write own loader if data fits on GPU\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-official",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Below, we construct a fully connected neural network. Here, we will limit ourselves to a single hidden layer, i.e., it's a shallow rather than deep neural network. To construct a neural network in PyTorch, we define a class that inherits from the nn.Module class. \n",
    "\n",
    "The class contains two functions:\n",
    "\n",
    "1) init: Defines all the objects we will need.\n",
    "\n",
    "2) forward: puts all of these objects together, defining the network architecture. Basically, x starts out as your input tensor and is transformed step by step as it passes through each layer of the network. In this notebook, we consider MNIST images as our input tensors. Each image contains 28x28 pixels. The fully connected layers of the neural network, however, can only deal with one-dimensional feature vectors. So, we flatten the tensor, x, which is then passed on to the first fully connected layer, fc1. After the first fully connected layer, a Rectified Linear Unit (ReLU) activation function is applied element-wise to the tensor. The tensor is then passed through the second fully connected layer, fc2. After passing through the second fully connected layer, the transformed x is returned. The final tensor (x) represents the output of the neural network, which can be used for tasks like classification (you can rename x if you don't want to call the input and the output the same or if you want to distinguish between feature extraction and the final classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "individual-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-parts",
   "metadata": {},
   "source": [
    "You can now create an instance of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "banner-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-choice",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "We now want to train the weights of the neural network. For this purpose, we first need to define what a good fit to data entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stupid-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-distribution",
   "metadata": {},
   "source": [
    "Secondly, we need to decide how we want to optimise the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "promising-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-string",
   "metadata": {},
   "source": [
    "Now, we are ready to train the neural network. Let's train for 5 epochs. Note that fixing the number of epochs in this manner is not a good choice and will lead to under- or overfitting. But in this notebook, we merely want to understand the basic concepts behind training a neural network.\n",
    "\n",
    "In each epoch, for each batch from the training set, we\n",
    "\n",
    "1) clear the accumulated gradients of the model parameters (accumulated during backpropagation),\n",
    "\n",
    "2) perform a forward run (i.e. we predict labels for the batch of images),\n",
    "\n",
    "3) compute the loss for these predictions,\n",
    "\n",
    "3) perform backpropagation,\n",
    "\n",
    "5) and use this to optimise the weights and biases of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-interpretation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.16252010849879142\n",
      "Epoch [2/5], Loss: 0.1526936502849802\n",
      "Epoch [3/5], Loss: 0.144004159595104\n",
      "Epoch [4/5], Loss: 0.14220418911030952\n",
      "Epoch [5/5], Loss: 0.14520296237253127\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# Training loop \n",
    "model.train()  # Set the model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    # !!!!!!!!!!!!!!!!!!!!! IMPORTANT !!!!!!!!!!!!!!!!!!!!!\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        labels = labels.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        # optimizer.zero_grad() # zero the parameter gradients\n",
    "        # outputs = model(images) #.to(\"cpu\") # forward run\n",
    "        # loss = criterion(outputs, labels) # compare to ground truth\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float32):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) \n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step() # update weights and biases\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    # !!!!!!!!!!!!!!!!!!!!! IMPORTANT !!!!!!!!!!!!!!!!!!!!!\n",
    "    # Print average loss for the epoch\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-senegal",
   "metadata": {},
   "source": [
    "## Testing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-investing",
   "metadata": {},
   "source": [
    "Having trained the network, we can now test it on unseen data (the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-gravity",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m----> 7\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/repos/RCDS-Deep-Learning-CNN/PyTorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/RCDS-Deep-Learning-CNN/PyTorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[24], line 11\u001b[0m, in \u001b[0;36mSimpleNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[0;32m~/repos/RCDS-Deep-Learning-CNN/PyTorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/RCDS-Deep-Learning-CNN/PyTorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/repos/RCDS-Deep-Learning-CNN/PyTorch/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on the test set: {100 * accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-ethernet",
   "metadata": {},
   "source": [
    "That's a pretty high accuracy, reflecting that the MNIST dataset is relatively simple and well-behaved. Indeed, you can do much better. CNNs can reach an accuracy of more than 99 per cent (see [Kaggle](https://www.kaggle.com/code/cdeotte/how-to-choose-cnn-architecture-mnist)). To achieve such a high accuracy, we need to improve the architecture. We will do so in notebook 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-invite",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-training",
   "metadata": {},
   "source": [
    "**Exercise 1**: Here, we use the adam optimiser. Find out what other optimisers are available.\n",
    "\n",
    "**Exercise 2**: What do the hyperparameters (e.g. lr in adam) mean? Change lr to a higher value (e.g. 1) and rerun the notebook. Or to a lower value. What happens? Why?\n",
    "\n",
    "**Exercise 3**: Here, we use the cross entropy as the loss function. What is a loss function? And what is the cross entropy?\n",
    "\n",
    "**Exercise 4**: Integrate data augmentation techniques into the data preprocessing pipeline. This helps improve the model's generalisation.\n",
    "\n",
    "**Exercise 5**: Change the architecture of the neural network. Add more layers, increase the number of neurons, or try a different activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-franchise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
