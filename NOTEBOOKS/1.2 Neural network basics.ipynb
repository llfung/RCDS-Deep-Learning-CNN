{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "received-exercise",
   "metadata": {},
   "source": [
    "# 1.2 Neural network basics\n",
    "\n",
    "In this notebook, we construct a basic neural network in PyTorch. We attempt to only provide a bare-bone example for clarity. For another such example, please see [PyTorch's homepage](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n",
    "\n",
    "<!--\n",
    "- [Building the network](#Building-the-network)\n",
    "- [Training the network](#Training-the-network)\n",
    "- [Testing the network](#Testing-the-network)\n",
    "- [Exercises](#Exercises)\n",
    "-->\n",
    "\n",
    "First, we import the libraries and load the data. You have already seen this code in notebook 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "otherwise-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4db4df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# We load a training set\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# And withhold some data for testing\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=256, shuffle=True, num_workers=32, pin_memory=True) # Torch's default dataloader is sequential and slow. Use num_worker may speed up the process a bit, but still CPU-driven. Write own loader if data fits on GPU\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=256, shuffle=False,num_workers=32, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-official",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Below, we construct a fully connected neural network. Here, we will limit ourselves to a single hidden layer, i.e., it's a shallow rather than deep neural network. To construct a neural network in PyTorch, we define a class that inherits from the nn.Module class. \n",
    "\n",
    "The class contains two functions:\n",
    "\n",
    "1) init: Defines all the objects we will need.\n",
    "\n",
    "2) forward: puts all of these objects together, defining the network architecture. Basically, x starts out as your input tensor and is transformed step by step as it passes through each layer of the network. In this notebook, we consider MNIST images as our input tensors. Each image contains 28x28 pixels. The fully connected layers of the neural network, however, can only deal with one-dimensional feature vectors. So, we flatten the tensor, x, which is then passed on to the first fully connected layer, fc1. After the first fully connected layer, a Rectified Linear Unit (ReLU) activation function is applied element-wise to the tensor. The tensor is then passed through the second fully connected layer, fc2. After passing through the second fully connected layer, the transformed x is returned. The final tensor (x) represents the output of the neural network, which can be used for tasks like classification (you can rename x if you don't want to call the input and the output the same or if you want to distinguish between feature extraction and the final classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "individual-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-parts",
   "metadata": {},
   "source": [
    "You can now create an instance of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "banner-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-choice",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "We now want to train the weights of the neural network. For this purpose, we first need to define what a good fit to data entails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stupid-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-distribution",
   "metadata": {},
   "source": [
    "Secondly, we need to decide how we want to optimise the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "promising-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-string",
   "metadata": {},
   "source": [
    "Now, we are ready to train the neural network. Let's train for 5 epochs. Note that fixing the number of epochs in this manner is not a good choice and will lead to under- or overfitting. But in this notebook, we merely want to understand the basic concepts behind training a neural network.\n",
    "\n",
    "In each epoch, for each batch from the training set, we\n",
    "\n",
    "1) clear the accumulated gradients of the model parameters (accumulated during backpropagation),\n",
    "\n",
    "2) perform a forward run (i.e. we predict labels for the batch of images),\n",
    "\n",
    "3) compute the loss for these predictions,\n",
    "\n",
    "3) perform backpropagation,\n",
    "\n",
    "5) and use this to optimise the weights and biases of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-interpretation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.14813150471829353\n",
      "Epoch [2/500], Loss: 0.1485662338105922\n",
      "Epoch [3/500], Loss: 0.1443791460642155\n",
      "Epoch [4/500], Loss: 0.1359356439018503\n",
      "Epoch [5/500], Loss: 0.1328628104576405\n",
      "Epoch [6/500], Loss: 0.13048275499901874\n",
      "Epoch [7/500], Loss: 0.12598259422056218\n",
      "Epoch [8/500], Loss: 0.12325031424456455\n",
      "Epoch [9/500], Loss: 0.12934439190207644\n",
      "Epoch [10/500], Loss: 0.12137994424618305\n",
      "Epoch [11/500], Loss: 0.11353505360002214\n",
      "Epoch [12/500], Loss: 0.11586436912258889\n",
      "Epoch [13/500], Loss: 0.12071263809153374\n",
      "Epoch [14/500], Loss: 0.1127504761152445\n",
      "Epoch [15/500], Loss: 0.11715948677601966\n",
      "Epoch [16/500], Loss: 0.10989731203843939\n",
      "Epoch [17/500], Loss: 0.11211614618276028\n",
      "Epoch [18/500], Loss: 0.11359295153078881\n",
      "Epoch [19/500], Loss: 0.10897403921377151\n",
      "Epoch [20/500], Loss: 0.10302586025221551\n",
      "Epoch [21/500], Loss: 0.09980683736503124\n",
      "Epoch [22/500], Loss: 0.10208247919031914\n",
      "Epoch [23/500], Loss: 0.1032940223020442\n",
      "Epoch [24/500], Loss: 0.10606647302654196\n",
      "Epoch [25/500], Loss: 0.10361149216744493\n",
      "Epoch [26/500], Loss: 0.09498620694305035\n",
      "Epoch [27/500], Loss: 0.10579564514312338\n",
      "Epoch [28/500], Loss: 0.10237959112100145\n",
      "Epoch [29/500], Loss: 0.09819515937186302\n",
      "Epoch [30/500], Loss: 0.0959916015452844\n",
      "Epoch [31/500], Loss: 0.10312329254093322\n",
      "Epoch [32/500], Loss: 0.09934009280293546\n",
      "Epoch [33/500], Loss: 0.09326507788389288\n",
      "Epoch [34/500], Loss: 0.09472280602030297\n",
      "Epoch [35/500], Loss: 0.10118473747229957\n",
      "Epoch [36/500], Loss: 0.0958991565919937\n",
      "Epoch [37/500], Loss: 0.089484197648361\n",
      "Epoch [38/500], Loss: 0.09438897861920773\n",
      "Epoch [39/500], Loss: 0.08856282291260172\n",
      "Epoch [40/500], Loss: 0.0925988139188353\n",
      "Epoch [41/500], Loss: 0.09149287511852193\n",
      "Epoch [42/500], Loss: 0.09740403357179875\n",
      "Epoch [43/500], Loss: 0.09598732914854871\n",
      "Epoch [44/500], Loss: 0.09208212175822639\n",
      "Epoch [45/500], Loss: 0.095653915381495\n",
      "Epoch [46/500], Loss: 0.09020022575525527\n",
      "Epoch [47/500], Loss: 0.07762715545423488\n",
      "Epoch [48/500], Loss: 0.08237200159024685\n",
      "Epoch [49/500], Loss: 0.09420860578167312\n",
      "Epoch [50/500], Loss: 0.09327021278440953\n",
      "Epoch [51/500], Loss: 0.07516144569963217\n",
      "Epoch [52/500], Loss: 0.08225576289473696\n",
      "Epoch [53/500], Loss: 0.09746095756108457\n",
      "Epoch [54/500], Loss: 0.08586701506629903\n",
      "Epoch [55/500], Loss: 0.0883973572640977\n",
      "Epoch [56/500], Loss: 0.07442961319329891\n",
      "Epoch [57/500], Loss: 0.08410484301362266\n",
      "Epoch [58/500], Loss: 0.08255215263430109\n",
      "Epoch [59/500], Loss: 0.08164568470909875\n",
      "Epoch [60/500], Loss: 0.0844980588658376\n",
      "Epoch [61/500], Loss: 0.08442234719925104\n",
      "Epoch [62/500], Loss: 0.08333401972467595\n",
      "Epoch [63/500], Loss: 0.07158070072492069\n",
      "Epoch [64/500], Loss: 0.07955669222320332\n",
      "Epoch [65/500], Loss: 0.07731116175889335\n",
      "Epoch [66/500], Loss: 0.07765252485157961\n",
      "Epoch [67/500], Loss: 0.07844717294136261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x14ec70907ba0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/500], Loss: 0.08294161748775142\n",
      "Epoch [69/500], Loss: 0.07929779395381821\n",
      "Epoch [70/500], Loss: 0.08154240816118236\n",
      "Epoch [71/500], Loss: 0.08083965115724726\n",
      "Epoch [72/500], Loss: 0.08285128651781284\n",
      "Epoch [73/500], Loss: 0.08491711384478084\n",
      "Epoch [74/500], Loss: 0.0699440359118137\n",
      "Epoch [75/500], Loss: 0.0687047216565685\n",
      "Epoch [76/500], Loss: 0.07984105956919016\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "\n",
    "# Training loop \n",
    "model.train()  # Set the model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    # !!!!!!!!!!!!!!!!!!!!! IMPORTANT !!!!!!!!!!!!!!!!!!!!!\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        labels = labels.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        # optimizer.zero_grad() # zero the parameter gradients\n",
    "        # outputs = model(images) #.to(\"cpu\") # forward run\n",
    "        # loss = criterion(outputs, labels) # compare to ground truth\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float32):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) \n",
    "        writer.add_scalar('Loss/train', loss, epoch)\n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step() # update weights and biases\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    # !!!!!!!!!!!!!!!!!!!!! IMPORTANT !!!!!!!!!!!!!!!!!!!!!\n",
    "    # Print average loss for the epoch\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss}')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-senegal",
   "metadata": {},
   "source": [
    "## Testing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-investing",
   "metadata": {},
   "source": [
    "Having trained the network, we can now test it on unseen data (the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "perfect-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 95.3%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        labels = labels.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on the test set: {100 * accuracy}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-ethernet",
   "metadata": {},
   "source": [
    "That's a pretty high accuracy, reflecting that the MNIST dataset is relatively simple and well-behaved. Indeed, you can do much better. CNNs can reach an accuracy of more than 99 per cent (see [Kaggle](https://www.kaggle.com/code/cdeotte/how-to-choose-cnn-architecture-mnist)). To achieve such a high accuracy, we need to improve the architecture. We will do so in notebook 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-invite",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Here, we use the adam optimiser. Find out what other optimisers are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21b791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb335bd7",
   "metadata": {},
   "source": [
    "**Exercise 2**: What do the hyperparameters (e.g. lr in adam) mean? Change lr to a higher value (e.g. 1) and rerun the notebook. Or to a lower value. What happens? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793891d",
   "metadata": {},
   "source": [
    "lr = Learning rate; how big each optimisation step is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576c228",
   "metadata": {},
   "source": [
    "**Exercise 3**: Here, we use the cross entropy as the loss function. What is a loss function? And what is the cross entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c5c60",
   "metadata": {},
   "source": [
    "Other loss functions include MSE (for continuous target), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0103c10",
   "metadata": {},
   "source": [
    "**Exercise 4**: Integrate data augmentation techniques into the data preprocessing pipeline. This helps improve the model's generalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13be657",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise 5**: Change the architecture of the neural network. Add more layers, increase the number of neurons, or try a different activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d018f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomRotation(degrees=(-90, 90)),transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# We load a training set\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# And withhold some data for testing\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=256, shuffle=True, num_workers=32, pin_memory=True) # Torch's default dataloader is sequential and slow. Use num_worker may speed up the process a bit, but still CPU-driven. Write own loader if data fits on GPU\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=256, shuffle=False,num_workers=32, pin_memory=True)\n",
    "\n",
    "# Get the first batch from the data loader\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    img = images[i].permute(1, 2, 0)\n",
    "    axes[i].imshow(img, cmap=\"gray\")\n",
    "    axes[i].axis('off')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3768377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(28 * 28, 28*28)\n",
    "        self.fce = nn.Linear(28 * 28, 28*28*4)\n",
    "        self.fcc1 = nn.Linear(28*28*4, 28*28)\n",
    "        self.fcc2 = nn.Linear(28*28, 14*14)\n",
    "        self.fcc3 = nn.Linear(14*14, 7*7)\n",
    "        self.fcf = nn.Linear(7*7, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim=1)\n",
    "        # x = self.fc0(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.fce(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.fcc1(x)\n",
    "        # x = self.relu(x)\n",
    "        x = self.fcc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fcc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fcf(x)\n",
    "        return x\n",
    "    \n",
    "model = SimpleNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597263f",
   "metadata": {},
   "source": [
    "More parameters does not mean better! (It does not give less loss at all!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73e9dc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/205], Loss: 0.5220371238728787\n",
      "Epoch [2/205], Loss: 0.504475899199222\n",
      "Epoch [3/205], Loss: 0.4961781860666072\n",
      "Epoch [4/205], Loss: 0.4843355842093204\n",
      "Epoch [5/205], Loss: 0.4817128670342425\n",
      "Epoch [6/205], Loss: 0.4801069362366453\n",
      "Epoch [7/205], Loss: 0.47565597536716053\n",
      "Epoch [8/205], Loss: 0.47690476711760177\n",
      "Epoch [9/205], Loss: 0.47796816876594056\n",
      "Epoch [10/205], Loss: 0.47175676264661426\n",
      "Epoch [11/205], Loss: 0.468575442217766\n",
      "Epoch [12/205], Loss: 0.4694708157092967\n",
      "Epoch [13/205], Loss: 0.47089943733621153\n",
      "Epoch [14/205], Loss: 0.46915886047038624\n",
      "Epoch [15/205], Loss: 0.4675324727880194\n",
      "Epoch [16/205], Loss: 0.46744457153563806\n",
      "Epoch [17/205], Loss: 0.4666035890579224\n",
      "Epoch [18/205], Loss: 0.46695321043755145\n",
      "Epoch [19/205], Loss: 0.46682304917497836\n",
      "Epoch [20/205], Loss: 0.4666269654923297\n",
      "Epoch [21/205], Loss: 0.4670950729796227\n",
      "Epoch [22/205], Loss: 0.4654168178426458\n",
      "Epoch [23/205], Loss: 0.4612982332706451\n",
      "Epoch [24/205], Loss: 0.4644249596494309\n",
      "Epoch [25/205], Loss: 0.46417262845851004\n",
      "Epoch [26/205], Loss: 0.45670482922107614\n",
      "Epoch [27/205], Loss: 0.45710369247071286\n",
      "Epoch [28/205], Loss: 0.4601108719693853\n",
      "Epoch [29/205], Loss: 0.4598808523188246\n",
      "Epoch [30/205], Loss: 0.45869755871752477\n",
      "Epoch [31/205], Loss: 0.46207319460016616\n",
      "Epoch [32/205], Loss: 0.45878509625475455\n",
      "Epoch [33/205], Loss: 0.4616924964367075\n",
      "Epoch [34/205], Loss: 0.4560379279420731\n",
      "Epoch [35/205], Loss: 0.45972960515225186\n",
      "Epoch [36/205], Loss: 0.4566861624413348\n",
      "Epoch [37/205], Loss: 0.4523876635318107\n",
      "Epoch [38/205], Loss: 0.4590756908376166\n",
      "Epoch [39/205], Loss: 0.45812549172563755\n",
      "Epoch [40/205], Loss: 0.45801950502902905\n",
      "Epoch [41/205], Loss: 0.4557987384339596\n",
      "Epoch [42/205], Loss: 0.45330820971346913\n",
      "Epoch [43/205], Loss: 0.454632258668859\n",
      "Epoch [44/205], Loss: 0.45904742872461357\n",
      "Epoch [45/205], Loss: 0.4555611920483569\n",
      "Epoch [46/205], Loss: 0.45227168430673315\n",
      "Epoch [47/205], Loss: 0.45203157878936606\n",
      "Epoch [48/205], Loss: 0.45546321691350733\n",
      "Epoch [49/205], Loss: 0.4533661834737088\n",
      "Epoch [50/205], Loss: 0.45392709158836525\n",
      "Epoch [51/205], Loss: 0.4519509993969126\n",
      "Epoch [52/205], Loss: 0.45355763777773433\n",
      "Epoch [53/205], Loss: 0.4580371145238268\n",
      "Epoch [54/205], Loss: 0.45643612450741705\n",
      "Epoch [55/205], Loss: 0.4511365180319928\n",
      "Epoch [56/205], Loss: 0.4527232669769449\n",
      "Epoch [57/205], Loss: 0.4535372611055983\n",
      "Epoch [58/205], Loss: 0.4561355360010837\n",
      "Epoch [59/205], Loss: 0.45046222159203064\n",
      "Epoch [60/205], Loss: 0.45179969097705597\n",
      "Epoch [61/205], Loss: 0.4529462698926317\n",
      "Epoch [62/205], Loss: 0.4480989380085722\n",
      "Epoch [63/205], Loss: 0.4506430946766062\n",
      "Epoch [64/205], Loss: 0.4517308151468318\n",
      "Epoch [65/205], Loss: 0.453928797295753\n",
      "Epoch [66/205], Loss: 0.45117388957358423\n",
      "Epoch [67/205], Loss: 0.4518089158737913\n",
      "Epoch [68/205], Loss: 0.4496495518278568\n",
      "Epoch [69/205], Loss: 0.4515186461996525\n",
      "Epoch [70/205], Loss: 0.45371314020867043\n",
      "Epoch [71/205], Loss: 0.4524884090778675\n",
      "Epoch [72/205], Loss: 0.44912460535130605\n",
      "Epoch [73/205], Loss: 0.4479487093205148\n",
      "Epoch [74/205], Loss: 0.45062389525961366\n",
      "Epoch [75/205], Loss: 0.44637782561018113\n",
      "Epoch [76/205], Loss: 0.4516613718042982\n",
      "Epoch [77/205], Loss: 0.4441190691704446\n",
      "Epoch [78/205], Loss: 0.44810877594542\n",
      "Epoch [79/205], Loss: 0.44540889491426183\n",
      "Epoch [80/205], Loss: 0.445821232110896\n",
      "Epoch [81/205], Loss: 0.44729265900368387\n",
      "Epoch [82/205], Loss: 0.44594481181591117\n",
      "Epoch [83/205], Loss: 0.4468201794522874\n",
      "Epoch [84/205], Loss: 0.4487516792530709\n",
      "Epoch [85/205], Loss: 0.4515031604056663\n",
      "Epoch [86/205], Loss: 0.4499418651804011\n",
      "Epoch [87/205], Loss: 0.4450074858487921\n",
      "Epoch [88/205], Loss: 0.4423012145022128\n",
      "Epoch [89/205], Loss: 0.4526871347681005\n",
      "Epoch [90/205], Loss: 0.4424568793875106\n",
      "Epoch [91/205], Loss: 0.44857083191262914\n",
      "Epoch [92/205], Loss: 0.4467235158098505\n",
      "Epoch [93/205], Loss: 0.4485281674151725\n",
      "Epoch [94/205], Loss: 0.4462089049055221\n",
      "Epoch [95/205], Loss: 0.4412098454668167\n",
      "Epoch [96/205], Loss: 0.44121196650444194\n",
      "Epoch [97/205], Loss: 0.44527582767161916\n",
      "Epoch [98/205], Loss: 0.44573815160609304\n",
      "Epoch [99/205], Loss: 0.44418384940066236\n",
      "Epoch [100/205], Loss: 0.44355300423946786\n",
      "Epoch [101/205], Loss: 0.4401516561812543\n",
      "Epoch [102/205], Loss: 0.4449479616702871\n",
      "Epoch [103/205], Loss: 0.44893592862372705\n",
      "Epoch [104/205], Loss: 0.44695575211910493\n",
      "Epoch [105/205], Loss: 0.44491048975193753\n",
      "Epoch [106/205], Loss: 0.44331975071988206\n",
      "Epoch [107/205], Loss: 0.44729907804347097\n",
      "Epoch [108/205], Loss: 0.4415703484352599\n",
      "Epoch [109/205], Loss: 0.44775506270692705\n",
      "Epoch [110/205], Loss: 0.4444351891253857\n",
      "Epoch [111/205], Loss: 0.4440937403668749\n",
      "Epoch [112/205], Loss: 0.44583682734915553\n",
      "Epoch [113/205], Loss: 0.4436295568943024\n",
      "Epoch [114/205], Loss: 0.44787639696547327\n",
      "Epoch [115/205], Loss: 0.4441225349903107\n",
      "Epoch [116/205], Loss: 0.4427819369955266\n",
      "Epoch [117/205], Loss: 0.4418093538030665\n",
      "Epoch [118/205], Loss: 0.44139611213765245\n",
      "Epoch [119/205], Loss: 0.4435373544692993\n",
      "Epoch [120/205], Loss: 0.4464549467918721\n",
      "Epoch [121/205], Loss: 0.44258255489329074\n",
      "Epoch [122/205], Loss: 0.43765897662081615\n",
      "Epoch [123/205], Loss: 0.4388451616814796\n",
      "Epoch [124/205], Loss: 0.4450680732727051\n",
      "Epoch [125/205], Loss: 0.44273926691806065\n",
      "Epoch [126/205], Loss: 0.441082741732293\n",
      "Epoch [127/205], Loss: 0.4420662737907247\n",
      "Epoch [128/205], Loss: 0.44340776547472527\n",
      "Epoch [129/205], Loss: 0.445851886779704\n",
      "Epoch [130/205], Loss: 0.4437889909490626\n",
      "Epoch [131/205], Loss: 0.441114659639115\n",
      "Epoch [132/205], Loss: 0.44028284321440025\n",
      "Epoch [133/205], Loss: 0.4408669352531433\n",
      "Epoch [134/205], Loss: 0.4419005112445101\n",
      "Epoch [135/205], Loss: 0.44238556699549897\n",
      "Epoch [136/205], Loss: 0.4425892358130597\n",
      "Epoch [137/205], Loss: 0.4368579290014632\n",
      "Epoch [138/205], Loss: 0.44374848147656054\n",
      "Epoch [139/205], Loss: 0.43603754119670135\n",
      "Epoch [140/205], Loss: 0.441208837514228\n",
      "Epoch [141/205], Loss: 0.43961799652018446\n",
      "Epoch [142/205], Loss: 0.4420250367611013\n",
      "Epoch [143/205], Loss: 0.43947177998563075\n",
      "Epoch [144/205], Loss: 0.43946802996574563\n",
      "Epoch [145/205], Loss: 0.4422781326669328\n",
      "Epoch [146/205], Loss: 0.44202723845522457\n",
      "Epoch [147/205], Loss: 0.44214030440817487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x15379356bba0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [148/205], Loss: 0.4401644915976423\n",
      "Epoch [149/205], Loss: 0.43586913087266554\n",
      "Epoch [150/205], Loss: 0.4383368560608397\n",
      "Epoch [151/205], Loss: 0.43664550020339643\n",
      "Epoch [152/205], Loss: 0.43943516738871313\n",
      "Epoch [153/205], Loss: 0.4402377355605998\n",
      "Epoch [154/205], Loss: 0.44007655191928785\n",
      "Epoch [155/205], Loss: 0.44024184333517197\n",
      "Epoch [156/205], Loss: 0.44071899931481545\n",
      "Epoch [157/205], Loss: 0.440718027885924\n",
      "Epoch [158/205], Loss: 0.43817619021902693\n",
      "Epoch [159/205], Loss: 0.43682895746636896\n",
      "Epoch [160/205], Loss: 0.43746686425614867\n",
      "Epoch [161/205], Loss: 0.4348398743791783\n",
      "Epoch [162/205], Loss: 0.44014533770845293\n",
      "Epoch [163/205], Loss: 0.4389417681288212\n",
      "Epoch [164/205], Loss: 0.4373082721487005\n",
      "Epoch [165/205], Loss: 0.43903535870795557\n",
      "Epoch [166/205], Loss: 0.43815749414423677\n",
      "Epoch [167/205], Loss: 0.4391647141030494\n",
      "Epoch [168/205], Loss: 0.43397418349347217\n",
      "Epoch [169/205], Loss: 0.4378836865120746\n",
      "Epoch [170/205], Loss: 0.4390276954529133\n",
      "Epoch [171/205], Loss: 0.43908650076135675\n",
      "Epoch [172/205], Loss: 0.43693988437348225\n",
      "Epoch [173/205], Loss: 0.43950118346417205\n",
      "Epoch [174/205], Loss: 0.44032083052269955\n",
      "Epoch [175/205], Loss: 0.4364613602770136\n",
      "Epoch [176/205], Loss: 0.43676088097247673\n",
      "Epoch [177/205], Loss: 0.438417268306651\n",
      "Epoch [178/205], Loss: 0.4382712332492179\n",
      "Epoch [179/205], Loss: 0.4372216077561074\n",
      "Epoch [180/205], Loss: 0.4376238554082018\n",
      "Epoch [181/205], Loss: 0.43775377210150374\n",
      "Epoch [182/205], Loss: 0.4372717041918572\n",
      "Epoch [183/205], Loss: 0.43813533592731396\n",
      "Epoch [184/205], Loss: 0.43662963433468593\n",
      "Epoch [185/205], Loss: 0.43928631233408094\n",
      "Epoch [186/205], Loss: 0.43722390633948305\n",
      "Epoch [187/205], Loss: 0.43712873293998394\n",
      "Epoch [188/205], Loss: 0.43596192547615537\n",
      "Epoch [189/205], Loss: 0.43527076066808496\n",
      "Epoch [190/205], Loss: 0.4368514361533713\n",
      "Epoch [191/205], Loss: 0.4356567620596987\n",
      "Epoch [192/205], Loss: 0.43787767608115014\n",
      "Epoch [193/205], Loss: 0.4367363049628887\n",
      "Epoch [194/205], Loss: 0.4323478285302507\n",
      "Epoch [195/205], Loss: 0.4355515051395335\n",
      "Epoch [196/205], Loss: 0.43541496091700616\n",
      "Epoch [197/205], Loss: 0.43886905705675167\n",
      "Epoch [198/205], Loss: 0.44049966018250647\n",
      "Epoch [199/205], Loss: 0.4361991837937781\n",
      "Epoch [200/205], Loss: 0.43801299777436764\n",
      "Epoch [201/205], Loss: 0.43643163975248944\n",
      "Epoch [202/205], Loss: 0.43630438408953076\n",
      "Epoch [203/205], Loss: 0.43793856362079053\n",
      "Epoch [204/205], Loss: 0.439671538992131\n",
      "Epoch [205/205], Loss: 0.43245572853595654\n",
      "Accuracy on the test set: 86.61999999999999%\n"
     ]
    }
   ],
   "source": [
    "# Criterion\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "# Optimiser\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 205\n",
    "\n",
    "# Training loop \n",
    "model.train()  # Set the model to training mode\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    # !!!!!!!!!!!!!!!!!!!!! IMPORTANT !!!!!!!!!!!!!!!!!!!!!\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        labels = labels.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        # optimizer.zero_grad() # zero the parameter gradients\n",
    "        # outputs = model(images) #.to(\"cpu\") # forward run\n",
    "        # loss = criterion(outputs, labels) # compare to ground truth\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.float32):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) \n",
    "        writer.add_scalar('Loss/train', loss, epoch)\n",
    "        loss.backward() # back propagation\n",
    "        optimizer.step() # update weights and biases\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    # !!!!!!!!!!!!!!!!!!!!! IMPORTANT !!!!!!!!!!!!!!!!!!!!!\n",
    "    # Print average loss for the epoch\n",
    "    average_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss}')\n",
    "\n",
    "writer.flush()\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        labels = labels.to(device, non_blocking=True) # SLOW!! # Move data from CPU to the GPU in parallel by num_workers in the DataLoader\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy on the test set: {100 * accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
